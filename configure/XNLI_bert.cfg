[model]
name = mBERT.all
test = False

[dataset]
train = data/hinglish_train.tsv
dev = data/hinglish_dev.tsv
test = data/xnli_test_hi.tsv data/xnli_test_en.tsv
tokenizer = bert-base-multilingual-cased

[eval]
task = XNLI
threshold = 0.5

[multi_bert]
location = bert-base-multilingual-cased

[train]
epoch = 10
batch = 32
seed = 42
gpu = True
max_save = 5
lr = 3e-5